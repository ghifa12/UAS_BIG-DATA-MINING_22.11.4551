# -*- coding: utf-8 -*-
"""TUGAS AKHIR SEMESTER_GHIFARY ZULVAN NOVIC_22.11.4551

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Jzj6llN-C_LkS8KV526okD2d8qiXqOeB

# Pendekatan Machine Learning dengan Model Random Forest untuk Klasifikasi Obesitas Berdasarkan Faktor Risiko Dan Gaya Hidup
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.preprocessing import StandardScaler, LabelEncoder
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score
from sklearn.feature_selection import SelectKBest, f_classif
import joblib

data = pd.read_csv('/content/ObesityDataSet.csv')

data.head()

data.info()

for col in data.columns:
    print(f"Column '{col}': {data[col].nunique()} unique values")

data.isna().sum()

source = "Dataset diambil dari Kaggle. berikut untuk tautan dari datasetnya."
print(f"Source: https://www.kaggle.com/datasets/fatemehmehrparvar/obesity-levels")

"""## 1. Data Preprocessing"""

# Bulatkan nilai pada kolom "Age" ke bawah
data['Age'] = data['Age'].astype(int)
data

# Encode categorical features
le = LabelEncoder()
for col in data.select_dtypes(include='object').columns:
    data[col] = le.fit_transform(data[col])

print(data.head())

# menstandarisasi fitur numerik
scaler = StandardScaler()
numerical_cols = data.select_dtypes(include=['int64', 'float64']).columns

# Kecualikan kolom target jika dalam numerical_cols
if 'NObeyesdad' in numerical_cols:
    numerical_cols = numerical_cols.drop('NObeyesdad')

data[numerical_cols] = scaler.fit_transform(data[numerical_cols])

data.head()

# Handle missing values
data.fillna(data.mean(), inplace=True)

data.head()

"""## 2. Exploratory Data Analysis (EDA)"""

categorical_features = data.select_dtypes(include=['int64', 'object']).columns

for feature in categorical_features:
    count = data[feature].value_counts()
    percent = 100 * data[feature].value_counts(normalize=True)
    dfu = pd.DataFrame({'Jumlah Sampel': count, 'Persentase': percent.round(1)})
    print(f"\n--- Distribusi untuk {feature} ---")
    print(dfu)
    count.plot(kind='bar', title=feature)
    plt.xlabel(feature)
    plt.ylabel('Jumlah Sampel')
    plt.show()

data.hist(bins=50, figsize=(20,15))
plt.show()

# Correlation heatmap
plt.figure(figsize=(12, 8))
sns.heatmap(data.corr(), annot=True, fmt='.2f', cmap='coolwarm')
plt.title("Correlation Heatmap")
plt.show()

"""## 3. Feature Selection"""

# memilih fitur terbaik dari dataset menggunakan metode SelectKBest
X = data.drop(columns=['NObeyesdad'])
y = data['NObeyesdad']
selector = SelectKBest(score_func=f_classif, k=10)
X_new = selector.fit_transform(X, y)
selected_features = X.columns[selector.get_support(indices=True)]

print("\n--- Selected Features ---")
print(selected_features)

# Update dataset with selected features
X = X[selected_features]

"""## 4. Modeling"""

# Split data
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# Build Random Forest Model
model = RandomForestClassifier(random_state=42)
model.fit(X_train, y_train)

# Save the model
joblib.dump(model, "random_forest_model.pkl")
print("Model saved as random_forest_model.pkl")

"""## 5. Evaluasi Model"""

# Predictions
y_pred = model.predict(X_test)

# Confusion Matrix
RF_cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(RF_cm, annot=True, fmt="d", cmap="Blues")
plt.title("Confusion Matrix")
plt.xlabel("Predicted Labels")
plt.ylabel("Actual Labels")
plt.show()

#classification Report
print("\nClassification Report:")
print(classification_report(y_test, y_pred))

# Hasil akurasi model
test_accuracy = accuracy_score(y_test, y_pred)
print(f"\nTest Accuracy: {test_accuracy * 100:.2f}%")